{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d677943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top similar recipes to 'bhel puri':\n",
      "['khakhra chaat', 'split bengal gram dal channa dal', 'oniongreen chilli paranthaparatha pyaaz aur hari mirch ka paranthaparatha', 'vegetarian nargisi kofta curry', 'potato samosa aloo ka samosa']\n",
      "Top similar recipes to 'grilled chicken':\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# ---------------------------\n",
    "# Load and clean the dataset\n",
    "# ---------------------------\n",
    "df = pd.read_excel('data/recipes.xlsx')\n",
    "df = df[['recipe_name', 'food_name_org']].copy()\n",
    "df = df.dropna(subset=['recipe_name'])\n",
    "df['food_name_org'] = df['food_name_org'].fillna('')\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower().strip()\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text\n",
    "\n",
    "df['recipe_name'] = df['recipe_name'].apply(clean_text)\n",
    "df['food_name_org'] = df['food_name_org'].apply(clean_text)\n",
    "\n",
    "# ---------------------------\n",
    "# Combine all ingredient names per recipe\n",
    "# ---------------------------\n",
    "recipes_grouped = (\n",
    "    df.groupby('recipe_name')['food_name_org']\n",
    "    .apply(lambda x: ' '.join(x))\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "recipes_grouped = recipes_grouped.drop_duplicates(subset=['recipe_name']).reset_index(drop=True)\n",
    "\n",
    "# ---------------------------\n",
    "# TF-IDF representation\n",
    "# ---------------------------\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf_matrix = tfidf.fit_transform(recipes_grouped['food_name_org'])\n",
    "\n",
    "# Compute cosine similarity\n",
    "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
    "\n",
    "# ---------------------------\n",
    "# Function to get similar recipes\n",
    "# ---------------------------\n",
    "def get_similar_recipes(recipe_name, cosine_sim=cosine_sim, recipes=recipes_grouped):\n",
    "    recipe_name = clean_text(recipe_name)\n",
    "    if recipe_name not in recipes['recipe_name'].values:\n",
    "        return []\n",
    "\n",
    "    idx = recipes[recipes['recipe_name'] == recipe_name].index[0]\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)[1:6]\n",
    "    return [recipes.iloc[i[0]]['recipe_name'] for i in sim_scores]\n",
    "\n",
    "# ---------------------------\n",
    "# Test the model\n",
    "# ---------------------------\n",
    "results1 = get_similar_recipes('bhel puri')\n",
    "print(\"Top similar recipes to 'bhel puri':\")\n",
    "print(results1)\n",
    "\n",
    "#\n",
    "results2 = get_similar_recipes('Bhel Poori')\n",
    "print(\"Top similar recipes to 'grilled chicken':\")\n",
    "print(results2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d66721f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['shepherds pie with minced meat',\n",
       " 'spinach and potato palak aloo',\n",
       " 'vegetable soup',\n",
       " 'stuffed tomatoes bharwa tamatar',\n",
       " 'potato with curd']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recipes_by_ingredients(ingredients, tfidf=tfidf, tfidf_matrix=tfidf_matrix, recipes=recipes_grouped):\n",
    "    ingredients = clean_text(ingredients)\n",
    "    ingredients_vec = tfidf.transform([ingredients])\n",
    "    sim_scores = cosine_similarity(ingredients_vec, tfidf_matrix).flatten()\n",
    "    top_indices = sim_scores.argsort()[::-1][:5]\n",
    "    return recipes.iloc[top_indices]['recipe_name'].tolist()\n",
    "get_recipes_by_ingredients(\"potato tomato onion\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fb7ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pickle\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "DATA_PATH = Path(\"data/recipes.xlsx\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"  \n",
    "BATCH_SIZE = 64                   \n",
    "TOP_PREFILTER = 200               \n",
    "MIN_SCORE = 0.30                  \n",
    "SEM_FUZZY_WEIGHT = (0.7, 0.3)     \n",
    "# ---------- helpers ----------\n",
    "def normalize_text(s, keep_digits=False):\n",
    "\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.lower().strip()\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    if keep_digits:\n",
    "        s = re.sub(r\"[^0-9a-z\\s]\", \" \", s)\n",
    "    else:\n",
    "        s = re.sub(r\"[^a-z\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def find_col(df, options):\n",
    "    for name in options:\n",
    "        if name in df.columns:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing {DATA_PATH}. Put your recipes.xlsx in data/ or change DATA_PATH.\")\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "name_col = find_col(df, [\"recipe_name_orig\", \"recipe_name\", \"_recipe_name_orig\", \"RecipeName\", \"translatedRecipeName\", \"recipe_name_org\"])\n",
    "ing_col  = find_col(df, [\"ingredient_name_org\", \"ingredient_name\", \"ingredient\", \"Ingredient_Name\", \"food_name_org\", \"food_name\"])\n",
    "food_col = find_col(df, [\"food_name_org\", \"food_name\", \"food\", \"Food_Name\", \"translatedIngredients\"])\n",
    "\n",
    "if not name_col:\n",
    "    raise KeyError(\"No recipe name column found. Check your Excel headers (tried several options).\")\n",
    "\n",
    "def combine_row_text(row):\n",
    "    parts = []\n",
    "    if ing_col and ing_col in row and pd.notna(row[ing_col]):\n",
    "        parts.append(str(row[ing_col]))\n",
    "    if food_col and food_col in row and pd.notna(row[food_col]):\n",
    "        parts.append(str(row[food_col]))\n",
    "    return \" \".join(parts).strip()\n",
    "\n",
    "df = df.dropna(subset=[name_col]).reset_index(drop=True)\n",
    "df[\"combined_text\"] = df.apply(combine_row_text, axis=1)\n",
    "print(f\"Loaded {len(df)} rows. Using recipe-name column: '{name_col}'. ingredient/food columns: '{ing_col}', '{food_col}'\")\n",
    "\n",
    "grouped = (\n",
    "    df.groupby(name_col)[\"combined_text\"]\n",
    "      .apply(lambda texts: \" \".join([t for t in texts.astype(str) if t.strip() != \"\"]))\n",
    "      .reset_index(name=\"full_text\")\n",
    ")\n",
    "\n",
    "grouped[\"recipe_clean\"] = grouped[name_col].apply(lambda x: normalize_text(x if pd.notna(x) else \"\"))\n",
    "grouped[\"clean_text\"] = grouped[\"full_text\"].apply(lambda x: normalize_text(x if pd.notna(x) else \"\", keep_digits=True))\n",
    "\n",
    "print(f\"Number of unique recipes after grouping: {len(grouped)}\")\n",
    "if grouped[name_col].duplicated().any():\n",
    "    print(\"Warning: duplicate recipe names found after grouping. Consider using a unique id to distinguish.\")\n",
    "\n",
    "# ---------- load model & compute embeddings ----------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}. Model: {MODEL_NAME} (batch_size={BATCH_SIZE})\")\n",
    "model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "\n",
    "\n",
    "texts_to_encode = (grouped[\"recipe_clean\"] + \" \" + grouped[\"clean_text\"]).tolist()\n",
    "\n",
    "\n",
    "recipe_embeddings = model.encode(\n",
    "    texts_to_encode,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    convert_to_tensor=True,\n",
    "    show_progress_bar=True,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "if recipe_embeddings.dtype != torch.float32 and hasattr(recipe_embeddings, \"to\"):\n",
    "    recipe_embeddings = recipe_embeddings.to(torch.float32)\n",
    "\n",
    "np.save(MODELS_DIR / \"recipe_embeddings.npy\", recipe_embeddings.cpu().numpy())\n",
    "grouped.to_pickle(MODELS_DIR / \"recipes_mapping.pkl\")\n",
    "\n",
    "print(\"Saved embeddings and mapping to models/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b879fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ISHAAN\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 10271 rows. Recipe column: 'recipe_name', ingredient columns: 'ingredient_name_org', 'food_name_org'\n",
      "Number of unique recipes: 1015\n",
      "Using device: cpu\n",
      "Loaded embeddings and mapping from models/\n",
      "\n",
      "Search results:\n",
      "Cashewnut burfi (Kaju burfi/Kaju katli) (score=0.85)\n",
      "  Ingredients preview: kewra essence kewra essence kaju cashew nut anacardium occidentale sugar sugar white water water distilled fat ghee butter\n",
      "\n",
      "Khasta Kachori (score=0.7885)\n",
      "  Ingredients preview: fat oil sunflower\n",
      "\n",
      "Khoa ladoo (score=0.7827)\n",
      "  Ingredients preview: kewra essence kewra essence almonds almond prunus amygdalus desiccated coconut coconut kernal dry cocos nucifera pistachionut pistachio nuts pistacla vera khoa khoa castor sugar sugar icing\n",
      "\n",
      "Bottle gourd burfi (Ghiya/Lauki burfi) (score=0.7557)\n",
      "  Ingredients preview: color green colour kewra essence kewra essence ghia bottle gourd elongate pale green lagenaria vulgaris khoya khoa sugar sugar white water water distilled fat ghee butter fat ghee butter\n",
      "\n",
      "Danedar burfi (score=0.7417)\n",
      "  Ingredients preview: kewra essence kewra essence cashewnuts cashew nut anacardium occidentale pistachionut pistachio nuts pistacla vera milk milk whole cow lemon lemons flesh only raw weighed with peel and pips sugar sugar white\n",
      "\n",
      "Bottle gourd kheer (Ghiya/Lauki kheer) (score=0.7392)\n",
      "  Ingredients preview: bottle gourd bottle gourd elongate pale green lagenaria vulgaris green cardamom cardamom green elettaria cardamomum almonds almond prunus amygdalus milk milk whole cow sugar sugar white\n",
      "\n",
      "Pumpkin coconut burfi (Kaddu aur nariyal ki burfi) (score=0.7385)\n",
      "  Ingredients preview: kewra essence kewra essence pumpkin pumpkin orange round cucurbita maxima green cardamom cardamom green elettaria cardamomum desiccated coconut coconut kernal dry cocos nucifera sugar sugar white water water distilled ghee ghee butter\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Improved, fixed, and commented semantic + fuzzy recipe search\n",
    "# Save this as search_recipes.py and run. Adjust DATA_PATH and model_name as needed.\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# embeddings & fuzzy\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from rapidfuzz import fuzz\n",
    "\n",
    "# optional torch only used for device detection and saving/loading tensors\n",
    "import torch\n",
    "\n",
    "# ---------- config ----------\n",
    "DATA_PATH = Path(\"data/recipes.xlsx\")\n",
    "MODELS_DIR = Path(\"models\")\n",
    "MODELS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Choose model: strong but slow -> \"all-mpnet-base-v2\"; fast & decent -> \"all-MiniLM-L6-v2\"\n",
    "MODEL_NAME = \"all-MiniLM-L6-v2\"\n",
    "BATCH_SIZE = 64\n",
    "TOP_PREFILTER = 200\n",
    "MIN_SCORE = 0.30\n",
    "SEM_FUZZY_WEIGHT = (0.7, 0.3)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def normalize_text(s, keep_digits=False):\n",
    "    \"\"\"Lowercase, normalize unicode, remove punctuation.\"\"\"\n",
    "    if not isinstance(s, str):\n",
    "        return \"\"\n",
    "    s = s.lower().strip()\n",
    "    s = unicodedata.normalize(\"NFKD\", s)\n",
    "    if keep_digits:\n",
    "        s = re.sub(r\"[^0-9a-z\\s]\", \" \", s)\n",
    "    else:\n",
    "        s = re.sub(r\"[^a-z\\s]\", \" \", s)\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def find_col(df, options):\n",
    "    for name in options:\n",
    "        if name in df.columns:\n",
    "            return name\n",
    "    return None\n",
    "\n",
    "# ---------- load data ----------\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Missing {DATA_PATH}\")\n",
    "\n",
    "df = pd.read_excel(DATA_PATH)\n",
    "\n",
    "name_col = find_col(df, [\n",
    "    \"recipe_name_orig\", \"recipe_name\", \"_recipe_name_orig\",\n",
    "    \"RecipeName\", \"translatedRecipeName\", \"recipe_name_org\"\n",
    "])\n",
    "ing_col = find_col(df, [\n",
    "    \"ingredient_name_org\", \"ingredient_name\", \"ingredient\",\n",
    "    \"Ingredient_Name\", \"food_name_org\", \"food_name\"\n",
    "])\n",
    "food_col = find_col(df, [\n",
    "    \"food_name_org\", \"food_name\", \"food\",\n",
    "    \"Food_Name\", \"translatedIngredients\"\n",
    "])\n",
    "\n",
    "if not name_col:\n",
    "    raise KeyError(\"No recipe name column found.\")\n",
    "\n",
    "def combine_row_text(row):\n",
    "    parts = []\n",
    "    if ing_col and pd.notna(row.get(ing_col)):\n",
    "        parts.append(str(row[ing_col]))\n",
    "    if food_col and pd.notna(row.get(food_col)):\n",
    "        parts.append(str(row[food_col]))\n",
    "    return \" \".join(parts).strip()\n",
    "\n",
    "df = df.dropna(subset=[name_col]).reset_index(drop=True)\n",
    "df[\"combined_text\"] = df.apply(combine_row_text, axis=1)\n",
    "\n",
    "print(\n",
    "    f\"Loaded {len(df)} rows. \"\n",
    "    f\"Recipe column: '{name_col}', ingredient columns: '{ing_col}', '{food_col}'\"\n",
    ")\n",
    "\n",
    "# ---------- group into one row per recipe ----------\n",
    "grouped = (\n",
    "    df.groupby(name_col)[\"combined_text\"]\n",
    "      .apply(lambda texts: \" \".join(t for t in texts.astype(str) if t.strip()))\n",
    "      .reset_index(name=\"full_text\")\n",
    ")\n",
    "\n",
    "grouped[\"recipe_clean\"] = grouped[name_col].apply(normalize_text)\n",
    "grouped[\"clean_text\"] = grouped[\"full_text\"].apply(\n",
    "    lambda x: normalize_text(x, keep_digits=True)\n",
    ")\n",
    "\n",
    "print(f\"Number of unique recipes: {len(grouped)}\")\n",
    "\n",
    "# ---------- load model ----------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "model = SentenceTransformer(MODEL_NAME, device=device)\n",
    "\n",
    "# ---------- load or compute embeddings ----------\n",
    "emb_path = MODELS_DIR / \"recipe_embeddings.npy\"\n",
    "map_path = MODELS_DIR / \"recipes_mapping.pkl\"\n",
    "\n",
    "texts_to_encode = (grouped[\"recipe_clean\"] + \" \" + grouped[\"clean_text\"]).tolist()\n",
    "\n",
    "if emb_path.exists() and map_path.exists():\n",
    "    recipe_embeddings = torch.from_numpy(np.load(emb_path)).to(device)\n",
    "    grouped = pd.read_pickle(map_path)\n",
    "    print(\"Loaded embeddings and mapping from models/\")\n",
    "else:\n",
    "    recipe_embeddings = model.encode(\n",
    "        texts_to_encode,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        convert_to_tensor=True,\n",
    "        show_progress_bar=True,\n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    if recipe_embeddings.dtype != torch.float32:\n",
    "        recipe_embeddings = recipe_embeddings.to(torch.float32)\n",
    "\n",
    "    np.save(emb_path, recipe_embeddings.cpu().numpy())\n",
    "    grouped.to_pickle(map_path)\n",
    "    print(\"Computed and saved embeddings to models/\")\n",
    "\n",
    "# ---------- semantic + fuzzy search ----------\n",
    "def search_recipe_semantic(\n",
    "    query,\n",
    "    top_k=5,\n",
    "    min_score=MIN_SCORE,\n",
    "    boost_keywords=None,\n",
    "    top_prefilter=TOP_PREFILTER,\n",
    "    sem_fuzzy_weight=SEM_FUZZY_WEIGHT\n",
    "):\n",
    "    q = normalize_text(query, keep_digits=True)\n",
    "\n",
    "    q_emb = model.encode(q, convert_to_tensor=True, device=device)\n",
    "    scores = util.cos_sim(q_emb, recipe_embeddings)[0].cpu().numpy()\n",
    "\n",
    "    # FIX 1: normalize semantic scores before blending\n",
    "    sem = scores\n",
    "    sem = (sem - sem.min()) / (sem.max() - sem.min() + 1e-8)\n",
    "\n",
    "    N = len(sem)\n",
    "    top_idx = np.argsort(-sem)[:min(top_prefilter, N)]\n",
    "\n",
    "    combined_scores = sem.copy()\n",
    "    sem_w, fuzzy_w = sem_fuzzy_weight\n",
    "\n",
    "    for i in top_idx:\n",
    "        # FIX 2: fuzzy match against name + ingredients\n",
    "        fuzz_text = (\n",
    "            str(grouped.loc[i, name_col]) + \" \" +\n",
    "            str(grouped.loc[i, \"clean_text\"])\n",
    "        )\n",
    "        fuzz_score = fuzz.partial_ratio(query, fuzz_text) / 100.0\n",
    "        combined_scores[i] = sem_w * sem[i] + fuzzy_w * fuzz_score\n",
    "\n",
    "        # FIX 3: keyword boost at scoring level\n",
    "        if boost_keywords:\n",
    "            for kw in boost_keywords:\n",
    "                if kw in grouped.loc[i, \"clean_text\"]:\n",
    "                    combined_scores[i] += 0.05\n",
    "\n",
    "    sorted_idx = np.argsort(-combined_scores)\n",
    "\n",
    "    out = []\n",
    "    for i in sorted_idx:\n",
    "        if len(out) >= top_k:\n",
    "            break\n",
    "        if combined_scores[i] < min_score:\n",
    "            continue\n",
    "        out.append({\n",
    "            \"recipe_name\": grouped.loc[i, name_col],\n",
    "            \"recipe_clean\": grouped.loc[i, \"recipe_clean\"],\n",
    "            \"score\": round(float(combined_scores[i]), 4),\n",
    "            \"ingredients_preview\": (\n",
    "                grouped.loc[i, \"clean_text\"][:250] +\n",
    "                (\"...\" if len(grouped.loc[i, \"clean_text\"]) > 250 else \"\")\n",
    "            )\n",
    "        })\n",
    "\n",
    "    # FIX 4: explicit fallback instead of silent failure\n",
    "    if not out:\n",
    "        fallback_idx = np.argsort(-sem)[:top_k]\n",
    "        for i in fallback_idx:\n",
    "            out.append({\n",
    "                \"recipe_name\": grouped.loc[i, name_col],\n",
    "                \"recipe_clean\": grouped.loc[i, \"recipe_clean\"],\n",
    "                \"score\": round(float(sem[i]), 4),\n",
    "                \"fallback\": True,\n",
    "                \"ingredients_preview\": (\n",
    "                    grouped.loc[i, \"clean_text\"][:250] +\n",
    "                    (\"...\" if len(grouped.loc[i, \"clean_text\"]) > 250 else \"\")\n",
    "                )\n",
    "            })\n",
    "\n",
    "    return out\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43b6eb6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search results:\n",
      "Chapati/Roti (score=0.9571)\n",
      "  Ingredients preview: whole wheat flour wheat flour atta triticum aestivum water water distilled ghee or butter ghee butter\n",
      "\n",
      "Masala vada (score=0.613)\n",
      "  Ingredients preview: channa dal bengal gram dal cicer arietinum arhar dal red gram dal cajanus cajan green chilli chillies green all varieties capsicum annum curry leaves curry leaves murraya koenigii ginger ginger fresh zingiber officinale onion onion big allium cepa fa...\n",
      "\n",
      "Paneer soup (score=0.6128)\n",
      "  Ingredients preview: cabbage cabbage green brassica oleracea var capitata f alba curry leaves curry leaves murraya koenigii garlic garlic small clove allium sativum black pepper pepper black piper nigrum mustard seed mustard seeds brassica nigra paneer paneer ginger ging...\n",
      "\n",
      "Methi malai paneer (score=0.6127)\n",
      "  Ingredients preview: kasoori methi fenugreek leaves trigonella foenum graecum peas shelled peas fresh pisum sativum onion onion big allium cepa black cardamom cardamom black elettaria cardamomum clove cloves syzygium aromaticum cashewnuts cashew nut anacardium occidental...\n",
      "\n",
      "Curd rice (Dahi bhaat/Dahi chawal/ Perugu annam/Daddojanam/Thayir saadam) (score=0.6093)\n",
      "  Ingredients preview: rice rice parboiled milled oryza sativa green chilli chillies green all varieties capsicum annum curry leaves curry leaves murraya koenigii ginger chopped ginger fresh zingiber officinale asafoetida asafoetida ferula assa foetida dry whole red chilli...\n",
      "\n",
      "Semolina cake (Suji/Rava cake) (score=0.6064)\n",
      "  Ingredients preview: rava suji wheat semolina triticum aestivum cardamom powder cardamom green elettaria cardamomum grated coconut coconut kernal dry cocos nucifera whole milk milk whole cow condensed milk milk condensed whole sweetened baking powder baking powder ghee g...\n",
      "\n",
      "Paneer parantha/paratha (score=0.5969)\n",
      "  Ingredients preview: whole wheat flour wheat flour atta triticum aestivum green chilli chillies green all varieties capsicum annum coriander leaves coriander leaves coriandrum sativum onion onion big allium cepa paneer paneer garam masala powder garam masala red chilli p...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    results = search_recipe_semantic(\n",
    "        \"chapati\",\n",
    "        top_k=7,\n",
    "        min_score=0.25,\n",
    "        boost_keywords=[\"curry\", \"rice\", \"indian\"]\n",
    "    )\n",
    "\n",
    "    print(\"\\nSearch results:\")\n",
    "    for r in results:\n",
    "        print(f\"{r['recipe_name']} (score={r['score']})\")\n",
    "        print(\"  Ingredients preview:\", r[\"ingredients_preview\"])\n",
    "        if r.get(\"fallback\"):\n",
    "            print(\"  [fallback result]\")\n",
    "        print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
